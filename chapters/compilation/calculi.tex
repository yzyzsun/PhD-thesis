\chapter{Formalization of the Compilation Scheme} \label{ch:calculi}

To demonstrate and validate the key ideas of the compilation scheme, this
chapter introduces two calculi for the source and the target languages,
respectively, and the elaboration between them.

The \emph{source calculus} is a variant of
\lambdaiplus~\citep{bi2018essence,huang2021taming}, which mainly omits
parametric polymorphism from \fiplus~\citep{bi2019distributive,fan2022direct},
the core calculus for CP. Polymorphism is supported in our compiler, and its
compilation is informally explained in \autoref{sec:poly}. We omit polymorphism
here because it adds considerable complications that would distract us from the
key ideas of the compilation scheme. Furthermore, our formalization does not
include most optimizations.

The \emph{target calculus} \lambdar is a standard $\lambda$-calculus that
supports extensible records, which can be regarded as a functional subset of
JavaScript.

In summary, the formalization includes the key idea of compiling merges to
type-indexed records, and the following improvements:
\begin{itemize}
\item The use of a new coercive style that avoids modeling coercions as function
      terms.
\item Avoiding coercions for record projections, which were needed by
      \citet{fan2022direct}.
\end{itemize}
Technical results include proofs of type safety, as well as several interesting
properties about our translation of types into record labels. All proofs are
mechanically checked using the Coq proof assistant and are available in the
supplementary materials.

\section{Target Calculus with Extensible Records}

As we have emphasized, our source language CP only allows disjoint traits in
trait composition. Correspondingly, our source calculus \lambdaiplus enforces
the disjointness constraint on merges and does not accept records with
overlapping fields. In contrast, the main characteristic of our \emph{target}
calculus \lambdar is that it allows duplicate labels in records. When labels
conflict, overriding happens, like the design of scoped labels by
\citet{leijen2005extensible}. But this overriding does not affect type safety
(with the existence of subtyping) or the coherence of the elaboration semantics.
This is because we only need to consider the terms that are generated by the
elaboration from our source calculus \lambdaiplus. Since labels are computed
from the corresponding source types of the fields, the type system of \lambdar
can require that duplicate labels in one record must be associated with fields
of \emph{equivalent} types. Besides, these fields are semantically equivalent
because they \emph{originate} from the same terms.

For instance, $[[1,,2]]$ and even $[[1,,1]]$ are forbidden in \lambdaiplus (and
our source language CP). Consequently, the elaborated terms in \lambdar cannot
have conflicting fields like $[[{int|=>1;int|=>2}]]$. However, it is possible,
as part of evaluation, that harmless forms of duplicate fields arise, leading to
duplicate fields where the values are the same, such as $[[{int|=>1;int|=>1}]]$.
We will discuss this harmless duplication and the coherence of the elaboration
semantics in \autoref{sec:duplicates} and \autoref{sec:coherence} after
presenting both calculi and the elaboration rules.

\paragraph{Syntax.}
We use the integer type as a representative of base types. $[[tBase]]$ denotes
the integer type, and $[[n]]$ represents any integer literal. The meta-variable
$[[r]]$ stands for record types, including the empty record type $[[{}]]$. The
type $[[r]]$ extended by a field of type $[[At]]$ with label $[[ll]]$ is written
as $[[{ll |=>At | r}]]$. For example, $[[{ll1 |=>At | {ll2|=>Bt | {}}}]]$ is a
record type with two fields and is abbreviated as $[[ {ll1 |=>At; ll2|=>Bt} ]]$.
In general, abbreviations $[[ { ll1 |=>At1 ; ... ; lln |=>Atn } ]]$ represents a
multi-field record type, and $[[ { ll1 |=> At1 ; ... ; lln |=> Atn | r } ]]$ is
the record type $[[r]]$ being extended by $n$ fields. At the term level, records
can be concatenated using $[[;;]]$, and $[[t.ll ]]$ extracts the first $[[ll]]$
field from $[[t]]$. The full syntax of \lambdar is as follows:\footnote{In our
Coq formalization, the bottom type and fixpoint expressions are also formalized
in both source and target calculi. We omit them in the paper to better align
with \lambdaiplus~\citep{bi2018essence}, which does not support these features.}
{ \small
    \begin{align*}
      &\text{Types}        &[[At]], [[Bt]], [[Ct]] \Coloneqq&~ [[tBase]] ~|~ [[At -> Bt]] ~|~ [[r]]  \\
      &\text{Record types} &[[r]]  \Coloneqq&~ [[{}]] ~|~ [[{ll |=> At | r}]]  \\
      &\text{Expressions}  &[[t]]  \Coloneqq&~ [[n]] ~|~ [[x]] ~|~
                                              [[\x.t]] ~|~ [[t1 t2]]
                                              ~|~[[ { ll1 |=> t1 ;
                                                    ... ; lln |=> tn } ]] ~|~ [[t.ll ]]~|~ [[t1;;t2]] \\
      &\text{Values}       &[[tv]] \Coloneqq&~ [[n]] ~|~ [[\x.t]] ~|~ [[ { ll1 |=> tv1 ; ... ; lln |=> tvn } ]] \\
      &\text{Typing contexts} &[[Gt]] \Coloneqq&~  \cdot ~|~ [[ Gt, x:At ]] %\\
      % &\text{Syntactic sugar} & [[{ll |=> At}]] \triangleq&~ [[{ll |=> At |{} }]] \\
      % &&[[ { ll1 |=> At1 ; ... ; lln |=> Atn | r  } ]] \triangleq&~ \{ [[ll1]] [[|=>]] [[At1]] \mid ... \{ [[lln]] [[|=>]] [[Atn]] \mid [[r]] \} ... \} \\
      % &&[[ { ll1 |=> At1 ; ... ; lln |=> Atn } ]] \triangleq&~ [[{ ll1 |=> At1 ; ... ; lln |=> Atn | {} } ]] \\
      % &&[[ { </ lli |=> Ati // i IN 1 .. n /> } ]] \triangleq&~ [[ { ll1 |=> At1 ; ... ; lln |=> Atn } ]] \\
      % &&[[ { </ lli |=> ti // i IN 1 .. n /> }]]  \triangleq&~  [[ { ll1 |=> t1 ; ... ; lln |=> tn } ]] \\
    \end{align*}
}

\begin{figure}[t]
  \small
  \ottdefnsTargetStep

  \begin{rulesection}{$[[ lookup ll tv1 => tv2]]$}{Label lookup on records}
    \begin{align*}
      [[ lookup ll { ll1 |=> tv1 ; ... ; lln |=> tvn }  => tvk ]]\;\;\qquad
      \text{if}\ [[llk=ll]]\ \text{and}\ \forall [[j]] \in 1 .. k\!\!-\!\!1, [[llj != ll]]\;\;
    \end{align*}
  \end{rulesection}

  \begin{rulesection}{$[[ lookup ll r => Bt]]$}{Label lookup on record types}
    \begin{align*}
      &[[ lookup ll {ll |=>At | r} => At ]]&&\\
      &[[ lookup ll1 {ll2 |=>At | r} => Bt ]]&&\text{if}\ [[ll1 != ll2]]\ \text{and}\ [[ lookup ll1 r => Bt ]]\\
      &[[ lookup ll1 {ll2 |=>At | r} =/> ]]&&\text{if}\ [[ll1 != ll2]]\ \text{and}\ [[ lookup ll1 r =/> ]]\\
      &[[ lookup ll {} =/> ]]&&
    \end{align*}
  \end{rulesection}

  \caption{Dynamic semantics and meta-functions for \lambdar.}
  \label{fig:target-eval}
\end{figure}

\paragraph{Small-step semantics.}
The dynamic semantics of target expressions is defined at the top of
\autoref{fig:target-eval}. For conciseness, we also use a list comprehension
representation $[[ { </ lli |=> ti // i /> } ]]$ for multi-field records. The
evaluation is call-by-value, and record fields are eagerly evaluated. To
concatenate two records, they have to be fully reduced to values and then merged
in \rref{TStep-Concat}. For example, $[[{ ll|=>1+1 } ;; t]]$ evaluates to
$[[{ ll |=> 2 ; ll1 |=> tv1 ; ... ; lln |=> tvn }]]$, assuming that $[[t]]$
evaluates to $[[{ ll1 |=> tv1 ; ... ; lln |=> tvn }]]$. \Rref{TStep-ProjRcd}
uses the lookup function ($[[lookup ll tv1 => tv2]]$) defined in the middle of
\autoref{fig:target-eval} to extract the first field with a matched label.

\paragraph{Type-level lookup.}
Besides the value-level lookup function, we define a meta-function on record
types at the bottom of \autoref{fig:target-eval} to reflect the behavior of
field selection. It finds the first field type that matches the given label,
just like the value-level one. We use $[[ lookup ll r =/> ]]$ to represent the
case where no field in $[[r]]$ matches $[[ll]]$.

\begin{figure}[t!]
  \small

  \begin{align*}
    &\text{Type equivalence} &[[At ~= Bt]] \quad\triangleq\quad& [[At <<: Bt]] \,\land\, [[Bt <<: At]] \\
  \end{align*}

  \ottdefnsRTSubtyping

  \begin{rulesection*}{$[[ lookup ll r ~= At ]]$,$[[ lookup ll r ~ At ]]$}{Abbreviations for lookup}
  \begin{align*}
    [[ lookup ll r ~= At]] \quad\triangleq\quad& \exists [[At']],\, [[lookup ll r => At']] \,\land\, [[At' ~= At]] \\
    [[ lookup ll r ~ At]]  \quad\triangleq\quad& [[lookup ll r ~= At]] \,\lor\, [[lookup ll r =/>]] \\
  \end{align*}
  \end{rulesection*}
  \ottdefnsWellformedCtx
  \ottdefnsWellformedTypes

  \caption{Width subtyping, type equivalence, and well-formedness in \lambdar.}
  \label{fig:target-subtype}
\end{figure}

\paragraph{Width subtyping.}
We define a form of width subtyping for record types at the top of
\autoref{fig:target-subtype}, while depth subtyping is not supported in
\lambdar. Intuitively, $[[ r1 <<: r2 ]]$ holds if, for any projection that can
be performed on a term of $[[r2]]$, it can also be performed on any term of
$[[r1]]$, and their results have equivalent types. The subtyping relation will
be used after we introduce our source calculus and its elaboration semantics in
the next section. In the metatheory proofs, we will need to relate record
expressions to parts of their types, like $[[{l=1 ; l'=true}]]$ to
$[[{ll|=>tBase}]]$. The relation between types and their parts is characterized
by width subtyping.

\paragraph{Equivalence of target types.}
An equivalence relation $[[~=]]$ is derived from width subtyping to allow
permutation of record fields. $[[ lookup ll r ~= At]]$ is an abbreviation for
the case where looking up $[[ll]]$ in $[[r]]$ produces a type equivalent to
$[[At]]$. A similar abbreviation $[[ lookup ll r ~ At]]$ additionally includes
the case where $[[ll]]$ is absent in $[[r]]$. An important property of
equivalent types is that they preserve the results of lookup:

\begin{lemma}[Lookup on equivalent types]\label{thm:lookup}
  Given $[[r1~=r2]]$: \begin{itemize}
  \item If $[[lookup ll r1 => Ct]]$ then $[[lookup ll r2 ~= Ct]]$.
  \item If $[[lookup ll r1 =/>]]$ then $[[lookup ll r2 =/>]]$.
  \end{itemize}
\end{lemma}

\paragraph{Type well-formedness.}
Well-formed types are defined at the bottom of \autoref{fig:target-subtype}.
Record type extension must be consistent: duplicate labels must be associated
with equivalent field types. Specifically, as shown by \rref{WF-Rcd}, to safely
extend type $[[r]]$ by a new field of label $[[ll]]$, either the old field type
in $[[r]]$ is equivalent to the new field type, or $[[r]]$ lacks label $[[ll]]$.
This is also enforced in the typing \rref{Typ-RcdCons}.

As we will explain later, every type in the source language, including an
intersection type, is translated into a record type in the target language. All
the record labels are generated from source types in the translation process,
where disjoint source types are converted to distinct labels. Although
overlapping is forbidden in merges, overlapping is \emph{not} forbidden in
intersection types. For example, $[[1,,2]]$ is forbidden but $[[tBase&tBase]]$
is a valid type in \lambdaiplus. Therefore, it is natural for corresponding
record types to contain duplicate labels. The properties of the source calculus
also ensure that the translated types are well-formed. With the well-formedness
restriction, permuting any fields in a record type does not affect type safety.

\begin{figure}[t]
  \small
  \ottdefnsConcatTypes
  \ottdefnsTargetTyping
  \caption{Typing of \lambdar.}\label{fig:target-typing}
\end{figure}

\paragraph{Typing.}
The typing rules of target expressions are presented in
\autoref{fig:target-typing}. A set of auxiliary rules is defined to concatenate
two record types ($[[r1 & r2 => r3]]$). The premise of \rref{CT-Rcd} guarantees
the well-formedness of the result type. Given the types of two record
expressions, the concatenation of the two record types directly reveals the
shape of the result of concatenating the two expressions.

In our type system, there is no subsumption rule or a rule that allows
conversion between $[[~=]]$-equivalent types. Every expression under the given
typing context has a unique type. That is, from a record type, it is
straightforward to tell the shape of its value: how many fields it has, what the
labels are, and how the fields are arranged. On the other hand, in
\rref{Typ-App}, the requirement on argument type is relaxed to
$[[~=]]$-equivalence.

\paragraph{Type soundness.}
The \lambdar calculus is proven to be type-sound via progress and type
preservation. However, we should emphasize that type preservation (and the
substitution lemma) is proven with respect to $[[~=]]$-equivalence.

\begin{theorem}[Progress]\label{thm:type-progress}
  If $[[ [] |-  t : At ]]$, then either $[[t]]$ is a value or
  $\exists [[t']]$, $[[t >-> t']]$.
\end{theorem}

\begin{lemma}[Substitution preserves typing]\label{thm:subst-term}
  If $[[Gt,x:At,Gt' |- t : Bt]]$ and $[[Gt|- t' : At']]$ and $[[ At' ~= At ]]$,
  then $\exists$ $[[Bt']]$ such that $[[Gt, Gt' |- t[x ~>> t']: Bt']]$ and $[[Bt' ~= Bt]]$.
\end{lemma}

\begin{theorem}[Type preservation]\label{thm:type-preservation}
  If $[[ [] |-  t : At ]]$ and $[[t >-> t']]$, then
  $\exists [[At']]$,
    $[[  []  |-  t' : At' ]]$ and $[[ At' ~= At ]]$.
\end{theorem}

\section{Source Calculus and Elaboration}

The source calculus is a variant of
\lambdaiplus~\citep{bi2018essence,huang2021taming}. It includes type $[[Top]]$,
the maximal element in subtyping, as well as its canonical value $[[top]]$.
Functions ($[[\x:A.e:B]]$) always have type annotations. $[[{l=e}]]$ stands for
single-field records, which has type $[[ {l:A} ]]$ if $[[e]]$ has type $[[A]]$.
The full syntax of \lambdaiplus is as follows:
{%\small
    \begin{align*}
      &\text{Types}        &[[A]], [[B]], [[C]] \Coloneqq&~ [[Top]]~|~ [[tBase]] ~|~ [[A -> B]] ~|~ [[ {l:A} ]] ~|~ [[A&B]] \\
      &\text{Expressions}    &[[e]]    \Coloneqq&~ [[top]] ~|~ [[n]] ~|~ [[x]] ~|~ [[\x:A.e:B]] ~|~ [[e1 e2]] ~|~ [[{l=e}]] ~|~ [[e.l]] ~|~ [[e1,,e2]] ~|~ [[e:A]]
    \end{align*}
}

\paragraph{Merge operator and disjoint intersection types.}
The symmetric merge operator ($[[,,]]$) is like record concatenation, with which
we can construct multi-field records from single-field records. However, it is
not restricted to records: as long as two expressions have \emph{disjoint} types
(i.e. they are thought to be compatible), $[[e1,,e2]]$ is allowed, containing
the information of both expressions. Assuming that $[[e1]]$ and $[[e2]]$ have
type $[[A]]$ and $[[B]]$ respectively, the whole merge has intersection type
$[[A&B]]$.
\begin{align*}
  [[ { l1 : A1; ...; ln : An } ]] \quad\triangleq\quad& [[ { l1 : A1 } ]] [[&]] ... [[&]] [[{ ln : An } ]] \\
  [[ { l1 = e1; ...; ln = en } ]] \quad\triangleq\quad& [[ { l1 = e1 } ]] [[,,]] ... [[,,]] [[ { ln = en } ]]
\end{align*}

\begin{figure}[b!]
  \small
  \ottdefnsTopLikeType
  \ottdefnsDisjoint
  \caption{Top-like types and type disjointness in \lambdaiplus.}\label{fig:disj}
\end{figure}

\paragraph{Top-like types and disjointness.}
\autoref{fig:disj} defines two relations. They follow the specifications in
previous work on disjoint intersection types~\citep{huang2021taming}, which are
defined in terms of coercive subtyping ($[[t1 : A <: B ~~> t2]]$) in
\autoref{fig:source-subtype} . Since we only need to consider the relation on
types, here we use $[[A<:B]]$ to represent the subtyping relation, ignoring the
terms $[[t1]]$ and $[[t2]]$.

\begin{theorem}[Coercion-erased subtyping]
  $[[A <: B]] \iff \forall [[t1]], \exists [[t2]], [[t1 : A <: B ~~> t2]]$.
\end{theorem}

At the top of \autoref{fig:disj} is the algorithmic definition of top-like types
($[[  toplike A ]]$). It characterizes types that are equivalent to $[[Top]]$,
including any function type with a top-like return type, and any record type
with a top-like field type. These types are thought to be vacuous and treated in
a unified way.

\begin{theorem}[Top-like types respect the specification]
  $[[toplike A]] \iff [[Top<:A]]$.
\end{theorem}

At the bottom of \autoref{fig:disj} is the algorithmic definition of
disjointness. We say two types are disjoint ($[[A*B]]$) if they do not overlap
on any meaningful types; or, any common supertypes they share are top-like.
Irrelevant types are considered disjoint, such as integer and function types, or
records with different labels. Function types are disjoint if and only if their
return types are disjoint. Two record types with the same label are disjoint if
and only if their field types are disjoint.

\begin{theorem}[Type disjointness respects the specification]\label{thm:disjoint}
  $[[A*B]]$ $\iff$
  $\forall C$, if $[[A<:C]]$ and $[[B<:C]]$ then $[[toplike C]]$.
\end{theorem}

\begin{figure}[b!]
  \small
  \begin{align*}
    &\text{Type indices}        &[[T]] ~\Coloneqq&~\, [[Base]] ~|~ [[Ts -> Ts]] ~|~ [[ {l:Ts} ]] \\
    &\text{List of type indices}&[[Ts]]~\Coloneqq&~\, [[ [T1,...,Tn] ]] \\
  \end{align*}

  \begin{minipage}{0.4\textwidth}
  \begin{rulesection}{$[[ | A | ]] = [[Ts]]$}{Translation to type indices}
  \begin{align*}
    [[ | A | ]] &= [[ [] ]] &\text{if $[[toplike A]]$} \\ % \text{ is toplike}\\
    %% [[ | Bot | ]] &= [[ [Bot] ]] &\\
    [[ | tBase | ]] &= [[ [Base] ]] &\\
    [[ | A->B | ]] &= [[ [|A|->|B|] ]] &\text{if not $[[toplike B]]$}\\%{(if }[[B]]\text{ is not toplike)}\\
    [[ | {l:A} | ]] &= [[ [{l : |A|}] ]] &\text{if not $[[toplike A]]$}\\ %\text{(if }[[A]]\text{ is not toplike)}\\
    [[ | A&B | ]] &= [[ dedup (mergesort |A| |B|) ]] \hspace*{-1cm}&
    %\\&&%\text{( [[dedup]] cancels duplicates in the sorted list)}\\
  \end{align*}
  \end{rulesection}
  \end{minipage}
  %% [[mergesort]] is the merge operation used in merge sort algorithm
  %%
  \hfill
  \begin{minipage}{0.5\textwidth}
  \begin{rulesection}{$[[ || A || ]] = [[r]]$}{Translation to target types}
  \begin{align*}
    [[ || A || ]] &= [[ {} ]] &\text{if $[[toplike A]]$} \\ %\text{(if }[[A]] \text{ is toplike)}\\
    %% [[ || Bot || ]] &= [[ { Bot |=>Bot } ]] &\\
    [[ || tBase || ]] &= [[ { Base |=>tBase } ]] &\\
    [[ || A->B || ]] &= [[ { |A|->|B| |=>||A|| -> ||B|| } ]] &\text{if not $[[toplike B]]$}\\% \text{(if }[[B]]\text{ is not toplike)}\\
    [[ || {l:A} || ]] &= [[ { { l : |A| } |=> ||A|| } ]] &\text{if not $[[toplike A]]$}\\ % \text{(if }[[A]]\text{ is not toplike)}\\
    [[ || A&B || ]] &= [[ r ]]  & \hspace*{-2cm} \text{if $[[ ||A|| & ||B|| => r ]]$} %\\
    %% [[||A||]] [[;;]] [[||B||]] & % \text\text{(} [[;;]] {is a meta-function that concatenates two record types)} \\ % \text{(if }[[ ||A|| & ||B|| => r ]]
  \end{align*}
  \end{rulesection}
  \end{minipage}
  \caption{Translation functions for types in \lambdaiplus.}\label{fig:translation}
\end{figure}

\paragraph{Type indices and translation functions.}
Merges in \lambdaiplus are elaborated into records in \lambdar. Each component
is tagged by a label, which we call a \emph{type index}. Type indices are
computed from the component types of an intersection. Defined in
\autoref{fig:translation}, the translation function $| \cdot |$ maps a type to
a list of type indices $[[Ts]]$. For types that are neither a top-like nor an
intersection type, the result is a singleton list. Values of top-like types are
thought to contain no information, so these types are omitted in translation,
i.e. they are converted into an empty list $[[ [] ]]$. These lists are merged in
the case of intersection types: $[[mergesort]]$ is a merge sort, taking two
sorted lists and producing a merged sorted list. Then we remove duplicates from
the result list using $[[dedup]]$. For example,
$[[tBase&(tBase->tBase)&tBase&(Top->Top)]]$ is translated to
$[[ [ Base, Base->Base ] ]]$. The list only contains the type indices for the
first two elements of the intersection type because the third element is a
duplicate of the first one and the last element is a top-like type. We use an
injective function to map each type index to a unique string in Coq, and we use
the alphabetical order of their corresponding strings to sort type indices.

\begin{lemma}[Translation]
  The mapping from type indices to strings has the following properties:
  \begin{itemize}
  \item If $ [[ |A1->B1| ]] =  [[ |A2->B2| ]]$ then $[[ |A1| = |A2| ]]$ and
    $[[ |B1| = |B2| ]]$, given that $[[A1->B1]]$ and $[[A2->B2]]$ are not top-like.
  \item If $ [[ |{l1:A1}| ]] =  [[ |{l2:A2}| ]]$ then $[[ l1 = l2 ]]$ and
    $[[ |A1| = |A2| ]]$, given that $[[ {l1:A1} ]]$ and $[[ {l2:A2} ]]$ are not top-like.
    \end{itemize}
\end{lemma}

To the right of the type-index translation function, there is another function
$\| \cdot \|$ that maps source types to target types. It uses the record type
concatenation defined in \autoref{fig:target-typing}. The function is based on
the design of elaboration, which we will introduce later (presented in
\autoref{fig:source-typing}). It reflects the type of the elaborated target
term. The result of translation is always a record type: all top-like types are
converted to the empty record type; converting an intersection type is
concatenating their counterparts. For the remaining types, the translation is a
record type tagged by the type index associated with the type itself. Only when
two field types are $[[~=]]$-equivalent, they can have the same type index.
While our typing rules use the type-index translation function  $| \cdot |$, the
type translation function $\| \cdot \|$ only serves the purpose of proving
metatheory properties.

\begin{figure}
  \small
  \begin{align*}
    &\text{Type equivalence} &[[A ~~ B]] \quad\triangleq\quad& [[A <<: B]] \,\land\, [[B <<: A]] \\
  \end{align*}
  \ottdefnsRSubtyping
  \caption{Width subtyping in \lambdaiplus.}\label{fig:source-equiv}
\end{figure}

\paragraph{Equivalence of source types.}
Corresponding to the $[[~=]]$-equivalence on target types, $[[~~]]$ defines an
equivalence relation on source types. Likewise, it is derived from a preorder
($[[A <<: B]]$), which is the width subtyping in the source calculus. Note that
it is not the subtyping used in the type system, but rather an auxiliary
relation defined to better characterize the invariant of the type index
translation. As defined in \autoref{fig:source-equiv}, this preorder relation is
stricter than the coercive subtyping used in our source type system (presented
in \autoref{fig:source-subtype}). An intersection type can be intuitively
understood as a set of distinct types. For example, the intersection type
$[[Bool&Char&(Int->Int)]]$ represents a set of three distinct elements:
$[[Bool]]$, $[[Char]]$, and $[[Int->Int]]$. Its width subtype must contain all
these three elements. Generally speaking, all component types in an intersection
must be present in its width subtype, excluding duplicates and top-like types.
The $[[~~]]$-equivalence groups types that map to the same type index.

\begin{lemma}[Equivalent types]\label{thm:trans}
  Some properties of the $[[~~]]$-equivalence can be derived from properties of width subtyping:
  \begin{itemize}
  \item If $[[lookup ll ||A|| => Ct1]]$ and $[[lookup ll ||B|| => Ct2]]$
    then $[[Ct1 <<: Ct2]]$.
    Thus, by symmetry, if $[[lookup ll ||A|| => Ct1]]$ and $[[lookup ll ||B|| => Ct2]]$
    then $[[Ct1 ~= Ct2]]$.
  \item $[[A <<: B]]$ if and only if all components of $[[| B |]]$ can be found in $[[| A |]]$.
    Thus, by symmetry, $[[A ~~ B]]$ if and only if  $[[| A | = | B |]]$.
  %% \item If $[[| A |]] \supseteq [[| B |]]$. Thus, if $[[| A | = | B |]]$ then $[[A ~~ B]]$.
  \item If $[[A <<: B]]$ then $[[|| A || <<: || B ||]]$. Thus, by symmetry,
    if $[[A ~~ B]]$ then $[[|| A || ~= || B ||]]$.
  \end{itemize}
\end{lemma}

\noindent
The first one is a strong result about type translation: in a translated type,
the type of a record field can be determined by its associated label. Hence, for
any two translated types $[[||A||]]$ and $[[||B||]]$, looking up the same label
$[[ll]]$ will lead to equivalent types $[[Ct1]]$ and $[[Ct1]]$. For example,
looking up an integer label $[[Base]]$ should always return an integer type
$[[tBase]]$. With the above properties, we can prove that all translated types
are well-formed.

\begin{lemma}[Well-formedness of translated types]\label{thm:wf-trans}
  $\forall A$, $[[ |- ||A|| ]]$.
\end{lemma}

\begin{figure}[t]
  \small
  \begin{align*}
    &\text{Typing contexts} &\quad[[G]] &\Coloneqq \cdot ~|~ [[ G, x:A ]] \\
    &\text{Typing modes} &\quad[[dirflag]] &\Coloneqq~ [[<=]] | [[=>]] \\
  \end{align*}

  \ottdefnsElaboration

  \caption{Type-directed elaboration of \lambdaiplus.}
  \label{fig:source-typing}
\end{figure}

\begin{figure}[t]
  \small

  \ottdefnsDistributiveApplication
  \ottdefnsProjection

  \caption{Distributive application and projection in \lambdaiplus.}
  \label{fig:source-dist}
\end{figure}

\paragraph{Type-directed elaboration.}
Defined in \autoref{fig:source-typing}, $[[G |- e dirflag A ~~> t]]$ relates a
source expression $[[e]]$ to a source type $[[A]]$ under the typing context
$[[G]]$ and the typing mode $[[dirflag]]$, and the typing derivation generates a
target expression $[[t]]$ from $[[e]]$. The type system is
\emph{bidirectional}~\citep{pierce2000local,dunfield2021bidirectional}: under
the inference mode ($[[=>]]$), $[[A]]$ is generated as an output; under the
checking mode ($[[<=]]$), $[[A]]$ is given as an input. Given the typing
context, every well-typed $[[e]]$ has a unique inferred type; all the types that
$[[e]]$ can be checked against are supertypes of this inferred type.

\Rref{Ela-Merge} is the signature rule of calculi with \emph{disjoint
intersection types}. The disjointness restriction on types ($[[A*B]]$, defined
in \autoref{fig:disj}) prevents the overlapping of components in a merge. Thus,
in a well-typed term like $[[e1]][[,,]] ... [[,,]][[en]]$, every subterm in the
merge has disjoint types. \Rref{Ela-Anno} allows upcasting expressions to any
supertypes. The subtyping relation is checked in \rref{Ela-Sub} via the
subtyping judgment $[[t1 : A <: B ~~> t2]]$, which also coerces the target term
$[[t1]]$ to $[[t2]]$. \Rref{Ela-App} relies on \emph{distributive application},
which is defined in \autoref{fig:source-dist}. It takes the
function type $[[A]]$ and the argument type $[[B]]$ and, if $[[A]]$ can be
applied to $[[B]]$, produces the return type $[[C]]$. Distributive application
additionally allows intersection types and top-like types (can be regarded as
0-ary intersections) to be applicable due to the distributivity of functions
over intersections. For example, $[[(A1->B1)&(A2->B2)]]$ can be applied to
$[[A1&A2]]$ and produces $[[B1&B2]]$.  Besides, $[[t1 : A ; t2 : B ~~> t3 : C]]$
uses $[[t1]]$ and $[[t2]]$ to generate the target term $[[t3]]$, reflecting the
application in the target language.  Similarly, \rref{Ela-Proj} relies on
\emph{distributive projection} to obtain the result type. Given a label $[[l]]$,
the relation $[[t1 : A ; { l } ~~> t2 : B]]$ finds all field types in $[[A]]$
that match $[[l]]$ and returns them as an intersection type $[[B]]$, if there is
more than one matched field. Similarly, $[[t2]]$ is the target expression that
extracts the corresponding fields in $[[t1]]$.

\Rref{Ela-Top,Ela-TopAbs,Ela-TopRcd} generate an empty record for top-like
types, which is a counterpart of the canonical top value. For non-top-like
types, \rref{Ela-Int,Ela-Abs,Ela-Rcd} produces records with a single label
translated from the type directly. Consequently, all elaborated terms are either
reducible or are in a record form.

\begin{figure}[t]
  \small
  \begin{align*}
    &\text{Ordinary types} &[[Aord]], [[Bord]], [[Cord]]\Coloneqq&~\, [[Top]] ~|~ [[tBase]] ~|~ [[A -> Bord]]  ~|~ [[{l:Aord}]] \\
  \end{align*}
  \ottdefnsCoSubtyping
  \caption{Coercive subtyping in \lambdaiplus.}\label{fig:source-subtype}
\end{figure}

\begin{figure}
  \small
  \ottdefnsSplitType
  \ottdefnsCoMerge
  \caption{Type splitting and coercive merging in \lambdaiplus.}\label{fig:source-split}
\end{figure}

\paragraph{Coercive subtyping.}
Defined in \autoref{fig:source-subtype}, $[[t1 : A <: B ~~> t2]]$ takes a target
expression $[[t1]]$ and two source types $[[A]]$ and $[[B]]$ and produces a
target term $[[t2]]$. Intuitively, when $[[t1]]$ has type $[[||A||]]$, the
generated $[[t2]]$ will have a type that is equivalent to $[[||B||]]$. The
formal theorem will be given later (\autoref{thm:ela-sound}) when establishing
type soundness. Besides producing the coerced target term, this relation also
checks whether $[[A]]$ is a subtype of $[[B]]$. For coercive subtyping, a more
common form of the judgment is $[[A<:B~~>c]]$, where $c$ is a coercion function
in the target language with type $[[||A||->||B||]]$. Instead of generating a
coercion function, we directly transform the term. The main motivation behind
our design is to generate more efficient terms: $[[t2]]$ can be understood as a
simplified result of the application $c~[[t1]]$. By adopting this technique, we
aim to skip some reduction steps, ultimately improving the performance of code
that relies on coercions. This idea has been discussed in
\autoref{sec:coercive}, and it is further optimized in \autoref{sec:elim}.

\Rref{S-Top} allows top-like types to be supertypes of any type and generates an
empty record regardless of the input term. This ensures that the overlapping of
disjoint types on the top-like part does not introduce ambiguity into the
semantics. However, this approach is not desirable if the language includes side
effects, because side effects would be ignored. Even in our purely functional
setting, a non-terminating expression would not be executed. It would be
interesting to investigate a better approach in the future.

To understand the subtyping check, we can ignore $[[t1]]$ and $[[t2]]$. In our
formulation of subtyping, type constructors like arrows and records distribute
over intersections, e.g. $[[A->B&C]]$ is equivalent to $[[(A->B)&(A->C)]]$. Such
distributivity first appeared in the system proposed by
\citet{barendregt1983filter} and is supported by \lambdaiplus and \fiplus. We
follow the subtyping algorithm design in \lambdaiplus~\citep{huang2021taming}.
It distinguishes types that have a form equivalent to intersection types from
others. Such types are called \emph{splittable types} and can be separated into
two via \emph{type splitting}, which is defined in \autoref{fig:source-split}.
For example, $[[split A->B&C A->B A->C]]$ represents that $[[A->B&C]]$ is
equivalent to the intersection of $[[A->B]]$ and $[[A->C]]$. The notation
$[[Aord]]$ stands for types that are not splittable, which are called
\emph{ordinary types}.

In type splitting, the two split types are outputs. However, they are then used
as inputs in the \emph{coercive merging} judgment $[[t1 : A |> C <| t2 : B ~~> t]]$,
as defined in \autoref{fig:source-split}. If we omit $[[t1]]$ and $[[t2]]$ in
this judgment, coercive merging characterizes the same relation as type
splitting. In other words, removing $[[split B B1 B2]]$ from \rref{S-Split} does
not change the idea of subtyping. We retain it to better represent the
information flow in the subtyping algorithm: in \rref{S-Split}, after being
generated from type splitting, $[[B1]]$ and $[[B2]]$ are used to coerce the same
term $[[e]]$ individually, and the coerced results $[[e1]]$ and $[[e2]]$ are
merged back, guided by the types. Note that, in this process, it is possible to
duplicate terms and lead to duplicate labels in the corresponding target record
terms.

\paragraph{Soundness of elaboration.}
The semantics of our source calculus is given via an elaboration, which reflects
the compilation of CP. We establish our type-safety proofs on (1) the type
safety of our target calculus, and (2) the soundness of elaboration, which
connects the source calculus to the target calculus. Specifically, for every
well-typed source expression, the typing derivation produces a target term, and
we prove that the target term is well-typed in the record calculus. In addition,
its type is equivalent to the translated type of the original source expression.
The soundness of elaboration is based on the soundness of coercive subtyping,
distributive application, and distributive projection, which guarantee that the
terms generated from these judgments have the desired types. Note that the
premises of these soundness lemmas are coarser than their conclusion: the actual
type of the input term does not have to be equivalent to the annotated type. For
example, in $[[t1 : A <: B ~~> t2]]$, $[[t1]]$ only needs to have a subtype of
$[[||A||]]$ for $[[t2]]$ to be correctly typed. This is because, in these
coercive relations, the input terms are always used for projection (e.g. in
\rref{S-Arrow,S-Rcd}) but never for concatenation. As long as the input terms
have sufficient fields, other fields that they have are unimportant.

\begin{theorem}[Elaboration soundness]\label{thm:ela-sound}
  We have that:
  \begin{itemize}
  \item If $[[t1 : A <: B ~~> t2]]$ and $[[  Gt |-  t1 : At ]]$ and $[[ At <<: ||A|| ]]$,
    then $\exists [[Bt]]$,
    $[[  Gt |-  t2 : Bt ]]$ and $[[ Bt ~= ||B|| ]]$.
  \item If $[[t1 : A ; t2 : B ~~> t3 : C]]$ and $[[  Gt |-  t1 : At ]]$ and $[[ At <<: ||A|| ]]$ and
    $[[  Gt |-  t2 : Bt ]]$ and $[[ Bt <<: ||B|| ]]$,
    then  $\exists [[Ct]]$,
    $[[  Gt |-  t3 : Ct ]]$ and $[[ Ct ~= ||C|| ]]$.
  \item If $[[t1 : A ; { l } ~~> t2 : B]]$ and $[[  Gt |-  t1 : At ]]$ and $[[ At <<: ||A|| ]]$,
    then  $\exists [[Bt]]$,
    $[[  Gt |-  t2 : Bt ]]$ and $[[ Bt ~= ||B|| ]]$.
  \item If $[[G |- e dirflag A ~~> t]]$ then $\exists [[At]]$,
    $[[ | G | |-  t : At ]]$ and $[[ At ~= ||A|| ]]$.
  \end{itemize}
\end{theorem}

\section{Duplicates in Translation and Coherence of Subtyping}
\label{sec:duplicates}

With the disjointness constraint enforced in \rref{Ela-Merge}, all elaborated
records originating from that rule have distinct labels. However, we still have
to take duplicates into account because they can be generated by coercive
subtyping. For example, $[[t:tBase<:tBase&tBase~~>t;;t]]$ duplicates $[[t]]$.
Note that given $[[t1]]$, $[[A]]$, and $[[B]]$, there could be more than a
single possible $[[t2]]$, generated by different derivations of subtyping
$[[t1 : A <: B ~~> t2]]$. Therefore, it is possible to have
$[[t1:A<:B&B~~>t2;;t3]]$ where $[[t2]]$ and $[[t3]]$ are different. In the proof
of \autoref{thm:ela-sound}, we show such results do not violate type
well-formedness: $[[t2]]$ and $[[t3]]$ have equivalent types. Moreover, we
conjecture that $[[t2]]$ and $[[t3]]$ have the same behavior, since similar
results have been proven in the past (semantic coherence or determinism) for
variants of \lambdaiplus~\citep{bi2018essence,huang2021taming}. Because the
disjointness restriction in \rref{Ela-Merge} ensures that semantically different
terms with equivalent types cannot be introduced into one merge, it is
sufficient to distinguish terms by the type indices.

\paragraph{Past coherence results.}
The technical reason for our coercive subtyping not producing a unique result is
that we allow types like $[[A1&A2]]$ even if a non-top-like type $[[B]]$ exists
such that $[[A1<:B]]$ and $[[A2<:B]]$ both hold, leading to two different
subtyping derivation paths for $[[A1&A2<:B]]$. One way to ensure the uniqueness
of coercions, as utilized by previous work, is to reject such intersection types
via a disjointness constraint in type
well-formedness~\citep{alpuim2017disjoint}. If intersection types are restricted
in this way, we do not even need to worry about duplicates at all. However,
unrestricted intersection types are more expressive and are required when
encoding bounded polymorphism~\citep{xie2020row}. Moreover, imposing a disjoint
constraint on all intersections significantly complicates the proof of type
soundness~\citep{alpuim2017disjoint}. That is why all subsequent
work~\citep{bi2018essence,bi2019distributive,huang2021taming,fan2022direct},
besides ours, relaxed the restriction on intersections.

For our source calculus to be coherent, it is necessary to ensure that all the
coercions generated from the same subtyping judgment are equivalent. Proving
this property is challenging, especially considering the main focus we had when
designing the formal calculi is to validate the compilation, for which the
efficiency is more important. In other words, many design choices in the
formalization are driven by efficiency considerations, rather than by
considerations for making a proof of coherence easier. For instance, we use a
novel and non-standard form of coercive subtyping. Nevertheless, the coherence
of the subtyping relation (and the determinism of the casting semantics implied
by subtyping) has already been proven in previous work on
\lambdaiplus~\citep{bi2018essence,huang2021taming}. Although our setting differs
slightly due to our use of a different target language, the previous results
about coherence provide us confidence that the elaboration here is also
coherent.

\paragraph{Determinism in a direct operational semantics.}
\citeauthor{huang2021taming}'s variant of \lambdaiplus uses a direct operational
semantics where annotations trigger subtyping checks and act as upcasts at run
time, directly manipulating source values. The upcasting process mirrors the
approach of algorithmic subtyping, which is similar to how coercions are
generated in our subtyping judgments. For instance, the expression
$[[1:Int&Int]]$ evaluates to $[[1,,1]]$. When an integer is expected, either
component can be selected. This type system permits duplicate components in
merges. The operational semantics of this variant has been proven to be
deterministic and type-safe, providing evidence that no ambiguity arises from
subtyping when using disjoint merges.

\paragraph{Coherence for an elaboration semantics.}
Closer to our work, \citeauthor{bi2018essence}'s variant of \lambdaiplus, also
known as \necolus, employs an elaboration semantics that is proven to be
coherent. The \necolus calculus covers the same set of expressions as our source
calculus and also features a syntax-directed bidirectional type system. It uses
a different algorithm to decide subtyping, and provides a formulation in
declarative style, which is equivalent to ours (see
\citeauthor{huang2021taming}'s work for a formalization of this result).  Most
of the typing rules are also the same as ours, including the rule for merges and
the subsumption rule.  The rules for lambda abstraction, application, and record
projection are slightly different in terms of requiring more or fewer type
annotations, and \necolus does not have the separate relations for distributive
application and projection.

The main difference between  \citeauthor{bi2018essence}'s elaboration and ours,
is that the target language for \necolus is a different calculus called
\lambdac. \lambdac is a variant of the simply typed $\lambda$-calculus extended
with records, products, and explicit coercions. In \necolus, merges are
translated into pairs. For example, $[[1,,true]]$ is translated into
$[[(1,true)]]$. In the coherence theorem, \citeauthor{bi2018essence} prove that
such elaboration always leads to equivalent terms in the target language. Their
proofs show that the duplication that arises in coercive subtyping does not
cause ambiguity in the target language.

Before discussing the coherence proof, let us compare the two elaboration
frameworks with some examples. Both \lambdac and our \lambdar only include the
integer type $[[tBase]]$ as a representative of primitive types, but we will use
$[[Bool]]$ and $[[Int]]$ in our examples for demonstration. Besides, we replace
the coercions in \lambdac by lambda terms and simplify all the elaboration
results for easier comparison. Furthermore, we include JavaScript code to show
the same situation in the code generated by our compiler.

\paragraph{Example 1.}
Consider the source expression:
\[
  [[1 : Int & Int : Int]]
\]
The translation to \lambdar is unique:
\[
  [[ { |Int| |=> { |Int| |=> 1 ; |Int| |=> 1 } . |Int| } ]]
\]
The translation to \lambdac has multiple possibilities, including:
\[
  [[(\x.x.fst) (1,1)]] \qquad\qquad [[(\x.x.snd) (1,1)]]
\]

\noindent
This example illustrates a challenging situation that involves two steps: first
creating a term corresponding to type $[[Int&Int]]$, and then selecting a
component of type $[[Int]]$. In \lambdar, the duplication in the first step
causes a label conflict, and the second step is deterministic because of the
overriding semantics; while in \lambdac, it is the second step that brings
potential ambiguity. With pairs serving as the target for merges in \lambdac,
every component in merges can be identified and extracted by position. The
position information is analyzed from types during the elaboration. If the merge
consists of two terms of the same type, the two positions can be used
interchangeably. Therefore, there are two possible coercions that can upcast
$[[Int&Int]]$ to $[[Int]]$, namely $[[\x.x.fst]]$ and $[[\x.x.snd]]$. Note that,
in a calculus with pairs, these two functions are clearly semantically different
since they can be applied to a pair argument like $[[(1,2)]]$, which would
produce two different results. But the point is that such pairs with different
elements of the same type are never produced by the elaboration, so these two
coercions behave identically for the \emph{pairs that can be generated from the
elaboration}.

This idea applies, more generally, to types with the same type index in our
elaboration, and not just syntactically equal types. Types with the same type
index are mutual subtypes and can interchange with each other in subtyping
derivation. Another observation from this example is that, whenever there is an
overriding in \lambdar, there will be multiple possibilities in the translation
to \lambdac.

Finally, the compiled JavaScript code (without optimization) is as follows:
\begin{lstlisting}[language=TypeScript,xleftmargin=.28\textwidth]
const $1 = {};  $1.int = 1;  $1.int = 1;
const $2 = {};  $2.int = $1.int;
\end{lstlisting}
The JavaScript code generated by our compiler shares the same overriding
semantics as \lambdar: \lstinline{$1.int} is assigned twice, and the second
assignment overrides the first one. Note that we have implemented several
optimizations in our compiler, including eliminating redundant coercions, so the
actual code generated by our compiler is more concise than the one shown here.
Since $[[Int&Int]]$ and $[[Int]]$ are equivalent types, no coercions will be
inserted in the optimized code. We keep the code unoptimized here to better
illustrate the correspondence between the JavaScript code and the \lambdar term.

\paragraph{Example 2.}
Consider another source expression:
\[
  [[ (\f.f) : (Int -> Int) & (Int -> Int&Bool) -> Int->Int ]]
\]
This time the translation to \lambdar has two possibilities. Here we use $[[A]]$
to denote the type $[[ (Int -> Int) & (Int -> Int&Bool) -> Int->Int ]]$:
\begin{align*}
  \{ & [[ | A | ]]  [[|=>]]
     [[ \f . {|Int->Int| |=> \x . { |Int| |=> ((f.|Int->Int|) { |Int| |=> x.|Int| }).|Int| } } ]] \} \\
  \{ & [[ | A | ]]  [[|=>]]
     [[ \f . {|Int->Int| |=> \x . { |Int| |=> ((f.|Int->Int&Bool|) { |Int| |=> x.|Int| }).|Int| } } ]] \}
\end{align*}
The two possibilities correspond to the translation to \lambdac as
follows:\footnote{ The \lambdac terms look much simpler because they are derived
from declarative subtyping for brevity. If we derive the coercions from
algorithmic subtyping, the terms will be more complicated:
\[
  [[ \x1. (\x2. (\x3 . \x4. (x3  x4) ) ((\x5. x5.fst) x2)) x1 ]]
\]
\[
  [[ \x1. (\x2. (\x4 . \x5. ((\x6.x6.fst) (x4  x5) )) ((\x7. x7.snd) x2)) x1 ]]
\]
}
\[
[[ \f. \x. f.fst x ]] \qquad\qquad [[ \f. \x. (f.snd x).fst ]]
\]

\noindent
This is a case where \lambdar has multiple syntactically different translation
results. The higher-order function expects a parameter $f$, which is a record in
\lambdar that has two fields with label $[[|Int->Int|]]$ and label
$[[|Int->Int&Bool|]]$. These two type indices are different, but the two types
are not disjoint. Therefore, if their common supertype is desired in a source
context, both fields can be selected. For the purpose of coherence, the two
results originating from both sides should behave the same; that is to say, they
should have equivalent semantics for the overlapping part of their types (i.e.
$[[Int->Int]]$). This is also needed for \lambdac: the two translated terms
should only apply to a pair of functions that have the same behavior, if we only
consider the integer part in their return results. Because of disjointness, the
only way to create a term with type $[[(Int -> Int) & (Int -> Int&Bool)]]$ is
using one lambda abstraction, such as
$[[(\x. x,,true) : Int -> Int&Bool :  (Int -> Int) & (Int -> Int&Bool)]]$. It
does not type-check to use a merge of two functions with types  $[[Int -> Int]]$
and $[[Int -> Int&Bool]]$ as these two types are not disjoint. Therefore, the
function that can be selected by the multiple coercions is the same function,
which was just duplicated twice.

The compilation to JavaScript may have two possible versions as well:

\noindent
\begin{minipage}{.5\textwidth}
\begin{lstlisting}[language=TypeScript]
const $1 = {};
$1.fun_fun_int = function ($f) {
  const $2 = {};
  $2.fun_int = function ($3) {
    const $4 = {};
    $4.int = $3.int;
    const $5 = $f.fun_int($4);
    const $6 = {};
    $6.int = $5.int;
    return $6;
  };
  return $2;
};
\end{lstlisting}
\end{minipage}%
\begin{minipage}{.5\textwidth}
\begin{lstlisting}[language=TypeScript]
const $1 = {};
$1.fun_fun_int = function ($f) {
  const $2 = {};
  $2.fun_int = function ($3) {
    const $4 = {};
    $4.int = $3.int;
    const $5 = $f['fun_(bool&int)']($4);
    const $6 = {};
    $6.int = $5.int;
    return $6;
  };
  return $2;
};
\end{lstlisting}
\end{minipage}

\noindent
Note that the only difference is the value of \lstinline{$5}: one is created by
applying \lstinline{$f.fun_int} and the other by applying
\lstinline[language=TypeScript]{$f['fun_(bool&int)']}
(n.b. \lstinline{$f.fun_(bool&int)} does not work because the label contains
special characters). The two versions will behave identically, so it does not
matter which one is actually generated. Similarly to the situation in \lambdar,
as long as the CP code is well-typed and is compiled to JavaScript by our
compiler, \lstinline{$f.fun_int} and
\lstinline[language=TypeScript]{$f['fun_(bool&int)']} originate from the same
function and behave the same as only the integer part of the return value  (i.e.
\lstinline{$5.int}) is used. Again, the JavaScript code is deliberately kept
unoptimized to show the correspondence with the \lambdar terms. In the optimized
code for the first version, for instance, the creation of \lstinline{$4} and
\lstinline{$6} can be eliminated.

\section{Coherence Proof for \necolus and Its Adaptation to Our Source Language}
\label{sec:coherence}

The coherence result in \necolus is established using a semantic approach based
on \emph{logical relations}~\citep{tait1967intensional,biernacki2015logical}.
Here we provide a summary of the key steps in that coherence proof. We will use
$E$, $V$, $\tau$, and $\Delta$ to represent the expressions, values, types, and
typing contexts in \lambdac, the target language for \necolus.

\paragraph{Coherence via contextual equivalence.}
The coherence theorem proven for \necolus is as follows:

\begin{theorem}[Coherence of \necolus]\label{thm:coherence}
If $\Gamma \vdash e \Leftrightarrow A$
then $\Gamma \vdash e \, {\simeq}_\mathit{ctx} \, e : A$.
\end{theorem}

\noindent
Here $e$ is a source expression, so it is to say that a well-typed source
expression is contextually equivalent to itself. The notation $\Leftrightarrow$
stands for both bidirectional typing modes, namely inference ($\Rightarrow$) and
checking ($\Leftarrow$). Contextual equivalence is defined as:

\begin{definition}[Contextual equivalence in \necolus]
$\Gamma \vdash e_1 \, {\simeq}_\mathit{ctx} \, e_2 :  A \;\triangleq$
\begin{align*}
\forall E_1\,E_2\,C\,D,\;
  & \textit{if}\ \Gamma \vdash e_1 \Leftrightarrow A \rightsquigarrow E_1 \ \textit{and}\ \Gamma \vdash e_2 \Leftrightarrow A \rightsquigarrow E_2
  \ \textit{and}\ C : (\Gamma \Leftrightarrow A) \mapsto (\cdot \Leftrightarrow [[tBase]]) \rightsquigarrow D \\
  & \textit{then}\ D[E_1] \simeq D[E_2].
\end{align*}
\end{definition}

\noindent
The intuition behind the definition is that two elaborated terms ($E_1$ and
$E_2$) should be considered equivalent if, for any well-typed contexts (that
could be generated during the elaboration), plugging either of them in makes no
difference to the final evaluation result. Here $C$ and $D$ stand for source and
target \emph{expression contexts}, respectively. An expression context is an
expression that contains a hole $[\cdot]$. The typing judgment for contexts
$C : (\Gamma \Leftrightarrow A) \mapsto (\cdot \Leftrightarrow [[tBase]]) \rightsquigarrow D$
means that, given any well-typed \necolus expression
$\Gamma \vdash e \Leftrightarrow A$, we have $\cdot \vdash C[e] \Leftrightarrow [[tBase]]$,
and the source context $C$ corresponds to a target context $D$ in elaboration,
which, similarly, make $D[E_1]$ and $D[E_2]$ have type $[[tBase]]$. In this
definition, $\simeq$ stands for Kleene equality. That is to say, $D[E_1]$ and
$D[E_2]$ evaluate to the same integer. Here the definition intentionally
excludes the contexts that cannot be obtained from a well-typed \necolus
expression. For example, the source expression $[[(\x.x) : tBase&tBase->tBase]]$
can be elaborated into $[[\x. x.fst]]$ or $[[\x. x.snd]]$. To judge whether they
have the same contribution to computation, we should not consider the target
expression context $[\cdot] [[(1,2)]]$, that is, applying the elaborated
function to $[[(1,2)]]$, because its corresponding source term violates the
disjointness restriction and thus is not well-typed.

\paragraph{Heterogeneous logical relations.}
\necolus introduces two heterogeneous logical relations that relates values and
terms, respectively, in the target language \lambdac, as shown in
\autoref{fig:logical-rel-lc}. The logical relation is designed to capture the
intuition of coherent expressions -- those that are safe to coexist in pairs, as
they are unambiguous in every valid context.

\begin{figure}
\begin{small}
\begin{align*}
  (V_1, V_2) &\in \mathcal{V} \llbracket [[tBase]]; [[tBase]] \rrbracket \; \triangleq \; \exists [[n]],\, V_1 = V_2 = [[n]] \\
  (V_1, V_2) &\in \mathcal{V} \llbracket \tau_1 \rightarrow \tau_2; \tau'_1 \rightarrow \tau'_2 \rrbracket \; \triangleq \; \forall (V, V') \in \mathcal{V} \llbracket \tau_1; \tau_1' \rrbracket,\, (V_1\,V, V_2\,V') \in \mathcal{E} \llbracket \tau_2; \tau'_2 \rrbracket \\
  (\{\ell = V_1\}, \{\ell = V_2\}) &\in \mathcal{V} \llbracket \{\ell : \tau_1\}; \{\ell : \tau_2\} \rrbracket \; \triangleq \; (V_1, V_2) \in \mathcal{V} \llbracket \tau_1; \tau_2 \rrbracket \\
  (\langle V_1, V_2 \rangle, V_3) &\in \mathcal{V} \llbracket \tau_1 \times \tau_2; \tau_3 \rrbracket \; \triangleq \; (V_1, V_3) \in \mathcal{V} \llbracket \tau_1; \tau_3 \rrbracket \land (V_2, V_3) \in \mathcal{V} \llbracket \tau_2; \tau_3 \rrbracket \\
  (V_3, \langle V_1, V_2 \rangle) &\in \mathcal{V} \llbracket \tau_3; \tau_1 \times \tau_2 \rrbracket \; \triangleq \; (V_3, V_1) \in \mathcal{V} \llbracket \tau_3; \tau_1 \rrbracket \land (V_3, V_2) \in \mathcal{V} \llbracket \tau_3; \tau_2 \rrbracket \\
  (V_1, V_2) &\in \mathcal{V} \llbracket \tau_1; \tau_2 \rrbracket \; \triangleq \; [[true]] \quad \text{otherwise} \\
  (E_1, E_2) &\in \mathcal{E} \llbracket \tau_1; \tau_2 \rrbracket \; \triangleq \; \exists V_1\,V_2,\, E_1 \! \rightarrow^* \! V_1 \land E_2 \! \rightarrow^* \! V_2 \land (V_1, V_2) \in \mathcal{V} \llbracket \tau_1; \tau_2 \rrbracket
\end{align*}
\end{small}
\caption{Logical relations for \lambdac (the target calculus of \necolus).}\label{fig:logical-rel-lc}
\end{figure}

First, $\mathcal{V} \llbracket \tau_1 ; \tau_2 \rrbracket$
relates all duplicate values. For example,
$([[1]],[[1]]) \in \mathcal{V} \llbracket [[tBase]] ; [[tBase]] \rrbracket$
because it never leads to ambiguity. Second, it is proven that all disjoint
values are also related. For example, as long as we have
$[[tBase * {l:tBase}]]$, we also have
$([[1]],[[{l=1}]]) \in \mathcal{V} \llbracket [[tBase]] ; [[{l:tBase}]] \rrbracket$.
For product types, the relation distributes over the product constructor
$\times$. This reflects the disjointness of intersection types, that is,
$[[A&B * C]]$ if and only if $[[A * C]]$ and $[[B * C]]$. Finally,
$\mathcal{E} \llbracket \tau_1 ; \tau_2 \rrbracket$ states that $E_1$ and $E_2$
are related if they evaluate to related values. The relation is then lifted to
open terms via a semantic interpretation of typing contexts, and the logical
equivalence is defined in a standard way: two open terms are related if every
pair of related closing substitutions make them related.
$\Delta \vdash E_1 \, {\simeq}_\mathit{log} \, E_2 :\tau$ denotes that two
well-typed expressions are logically equivalent with respect to the same typing
context and the same type.

\paragraph{Fundamental property.}
In \necolus, a fundamental property is proven, stating that any two \lambdac
terms elaborated from the same \necolus expression are related by the logical
relation. Here $\|\Gamma\|$ and $\|A\|$ stand for the translation of typing
contexts and types from \necolus to \lambdac.

\begin{theorem}[Fundamental property of \necolus]
  If \( \Gamma \vdash e \Leftrightarrow A \rightsquigarrow E_1 \)
  and \( \Gamma \vdash e \Leftrightarrow A \rightsquigarrow E_2 \),
  then \( \|\Gamma\| \vdash E_1 \, {\simeq}_\mathit{log} \, E_2 : \|A\| \).
\end{theorem}

\noindent
Note that $\Delta \vdash E \, {\simeq}_\mathit{log} \, E :\tau$ does not hold
for every well-typed target $E$. For example, the logical relation does not
consider $[[(1,2)]]$. Since there is no possible elaboration (the source
expression $[[1,,2]]$ violates the disjoint constraint), this does not prevent
the fundamental property. Actually the limitation on coherent products helps the
logical relation to accept some semantically equivalent terms like
$[[\x. x.fst]]$ and $[[\x. x.snd]]$: they are two translations of
$[[(\x.x) : Int&Int -> Int]]$. With the assumption that the two integers in the
pair argument are related by the logical relation, choosing either one leads to
the same result.

\paragraph{Soundness.}
Since the fundamental property has shown that different elaborations of the same
\necolus expression are logically equivalent, the remaining step is to show that
logical equivalence is sound with respect to contextual equivalence.

A compatibility lemma for coercions is proven during the establishment of the
fundamental property: if two terms are related by the logical relation, after
applying a coercion to one term, they are still related. Based on this lemma, we
can prove that the logical relation is preserved by all well-typed \necolus
contexts, including the contexts that coverts a term to an integer result, for
which the logical relation implies Kleene equality. Then it is straightforward
to show that the logical relation is sound.

\begin{theorem}[Soundness w.r.t. contextual equivalence in \necolus]
If \( \Gamma \vdash e_1 \Leftrightarrow A  \rightsquigarrow E_1 \)
and \( \Gamma \vdash e_2 \Leftrightarrow A  \rightsquigarrow E_2 \)
and \( \|\Gamma\| \vdash E_1 \, {\simeq}_\mathit{log} \, E_2 : \|A\| \),
then \( \Gamma \vdash e_1 \, {\simeq}_\mathit{ctx} \, e_2 : A \).
\end{theorem}

\noindent
Finally, the coherence theorem follows directly from the fundamental property
and the soundness result. In other words, we can conclude that any two \lambdac
terms elaborated from the same \necolus expression are contextually equivalent.

\paragraph{Adapting the proof to our source language: a sketch.}
While our compilation scheme makes some different design choices for efficiency,
it essentially shares the same principle of coherence with \necolus. Here we
provide a sketch of how to adapt the ideas from the \necolus proof to our work,
although we do not provide a full proof.

\begin{figure}
\begin{small}
\begin{align*}
  ([[tv1]], [[tv2]]) \in \mathcal{V_r} \llbracket [[tBase]]; [[tBase]] \rrbracket \;\triangleq\;& \exists [[n]],\, [[tv1]] = [[tv2]] = [[n]] \\
  ([[tv1]], [[tv2]]) \in \mathcal{V_r} \llbracket [[At1->Bt1]]; [[At2->Bt2]] \rrbracket \;\triangleq\;&
    \forall ([[tv]], [[tv']]) \in \mathcal{V_r} \llbracket [[At1]]; [[At2]] \rrbracket, \\
  & ([[tv1]]\,[[tv]], [[tv2]]\,[[tv']]) \in \mathcal{E_r} \llbracket [[Bt1]]; [[Bt2]] \rrbracket \\
  ( [[{ ll1 |=> tv1 } ]], [[{ ll2 |=> tv2 } ]]) \in \mathcal{V_r} \llbracket [[{ ll1 |=> At1} ]] ; [[{ ll2 |=> At2 }]] \rrbracket \;\triangleq\;&
    ([[tv1]], [[tv2]]) \in \mathcal{V_r} \llbracket [[At1]] ; [[At2]] \rrbracket \quad \text{if}\ [[ll1]]=[[ll2]]=[[Base]] \\
  &\text{or}\ (\exists[[Tsi]],\,[[ll1]]=[[ Ts1->Ts2 ]] \land [[ll2]]=[[ Ts3->Ts4 ]]) \\
  &\text{or}\ (\exists[[ll]]\,[[Tsi]],\,[[ll1]]=[[ {l: Ts1} ]] \land [[ll2]] = [[ {l: Ts2} ]]) \\
  ( [[{ ll1 |=> tv1 ; ... ; lln |=> tvn }]] , [[tv']]) \in \mathcal{V_r} \llbracket [[{ ll1 |=> At | r } ]] ; [[Bt]] \rrbracket \;\triangleq\;&
    ( [[{ ll1 |=> tv1 } ]] , [[tv']]) \in \mathcal{V_r} \llbracket [[{ ll1 |=> At } ]] ; [[Bt]] \rrbracket \; \land \\
  & ([[{ ll2 |=> tv2 ; ... ; lln |=> tvn } ]] , [[tv']]) \in \mathcal{V_r} \llbracket [[ r ]] ; [[Bt]] \rrbracket \\
  ( [[tv']] , [[{ ll1 |=> tv1 ; ... ; lln |=> tvn }]] ) \in \mathcal{V_r} \llbracket [[Bt]] ; [[{ ll1 |=> At | r } ]] \rrbracket \;\triangleq\;&
    ( [[tv']] , [[{ ll1 |=> tv1 } ]] ) \in \mathcal{V_r} \llbracket [[Bt]] ; [[{ ll1 |=> At } ]] \rrbracket \; \land \\
  & ( [[tv']] , [[{ ll2 |=> tv2 ; ... ; lln |=> tvn } ]] ) \in \mathcal{V_r} \llbracket [[Bt]] ; [[ r ]] \rrbracket \\
  ([[tv1]], [[tv2]]) \in \mathcal{V_r} \llbracket [[At1]]; [[At2]] \rrbracket \;\triangleq\;& [[true]] \quad \text{otherwise} \\
  ([[t1]], [[t2]]) \in \mathcal{E_r} \llbracket [[At1]]; [[At2]] \rrbracket \;\triangleq\;& \exists [[tv1]]\,[[tv2]],\, [[t1]] \! \rightarrow^* \! [[tv1]] \; \land \; [[t2]] \! \rightarrow^* \! [[tv2]] \; \land \\
  & \qquad\quad ([[tv1]], [[tv2]]) \in \mathcal{V_r} \llbracket [[At1]]; [[At2]] \rrbracket
\end{align*}
\end{small}
\caption{Logical relations for \lambdar (our target calculus).}\label{fig:logical-rel-lr}
\end{figure}

We can define two logical relations for values
($\mathcal{V_r} \llbracket [[At]] ; [[Bt]] \rrbracket$) and terms
($\mathcal{E_r} \llbracket [[At]]; [[Bt]] \rrbracket$) in \lambdar, as presented
in \autoref{fig:logical-rel-lr}. In this definition, we relate two records if
they do not cause ambiguity under any contexts that can be elaborated from our
source calculus. That is to say, for two records to be related, any pair of
fields from them, as long as their labels correspond to overlapping source
types, must have related fields. For example, relating
$ [[ { | Int -> Int&Bool | |=> tv1 } ]] $ and $[[{ | Int -> Int | |=> tv2 }]]$
in the logical relation requires $[[tv1]]$ and $[[tv2]]$ to be related.
Considering a source expression context $ [ \cdot ]: [[Int->Int]] $, it applies
to both records and leads to two projections that extract $[[tv1]]$ and
$[[tv2]]$, respectively. So $[[tv1]]$ and $[[tv2]]$ should be equivalent.
Besides, disjoint terms are also related. For example,
$ [[ { | {l1:A} | |=> tv1 } ]] $ and $ [[ { | {l2:B} | |=> tv2 } ]] $ correspond
to two source records of type $ [[ {l1:A} ]] $ and type $ [[ {l2:B} ]] $. If
$[[l1 = l2]]$, their relation should be decided by the fields; if
$[[l1 != l2]]$, they are always related because of disjointness. The relation of
terms can be lifted to open terms like in \necolus. We expect the logical
equivalence derived from the logical relation to be compatible with our coercive
subtyping, and a fundamental property should follow. The main rationale is that
the overlapping part must have the same origin, restricted by type disjointness.
What coercions do is to decompose and recompose the behaviors according to the
types (labels). Disjoint terms will be distinguished clearly in the process. A
field of $ [[ | {l1:A} | ]]$, for example, will not be used to build a field of
$ [[ | {l2:A} | ]]$ if $[[l1 != l2]]$. No \lambdaiplus context should violate
the derived logical equivalence. We anticipate a similar theorem asserting that
logical equivalence implies contextual equivalence, provided that contextual
equivalence is defined in a manner analogous to \necolus. Consequently, the
coherence theorem would follow, in the style of \autoref{thm:coherence}.
