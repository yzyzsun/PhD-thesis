\chapter{Conclusion and Future Work} \label{ch:conclusion}

The contributions of this thesis are threefold. First, it investigates the
application of compositional programming to embedded domain-specific languages
and object-oriented programming. Second, it presents our design and
implementation of the CP compiler, which efficiently compiles CP to JavaScript.
Third, it explores the extension of CP with union types for named and optional
arguments. We anticipate that the design principles and implementation
strategies proposed in this thesis will inform the development of future
programming languages that prioritize compositionality.

In the following sections, we discuss some future directions that are worth
exploring.

\section{Formalizing the Document DSL}

\newcommand{\DArtTLit}{$\mathcal{D}^\mathsf{Article}_\mathsf{TLit}$\xspace}
\newcommand{\DArtTProg}{$\mathcal{D}^\mathsf{Article}_\mathsf{TProg}$\xspace}
\newcommand{\kw}[1]{\text{\ttfamily\bfseries #1}}

\ExT, introduced in \autoref{sec:dsl}, is a powerful document DSL that supports
general-purpose computation. However, we only give an informal description of
\ExT without formalizing its semantics. Recently, \citet{crichton2024core}
proposed a core calculus for documents and provided a formal semantics for it.
It would be interesting to investigate the relationship between our \ExT and
their document calculus.

\citeauthor{crichton2024core} classified documents into eight levels based on
the document domain and expressiveness. According to their taxonomy, \ExT
corresponds to the article template literal calculus \DArtTLit, meaning that the
documents generated by \ExT are annotated trees of strings (called
``articles''), and documents are constructed of article literals with
interpolation, similar to Scribble in Racket.

To better understand the document calculus, we restate the definition of
templates in \DArtTLit below:
\begin{align*}
\mathsf{Template}^\mathsf{Article}_\mathsf{TLit} \; t&::= [p^*] \\
   \mathsf{TPart}^\mathsf{Article}_\mathsf{TLit} \; p&::= s ~|~ e ~|~ \kw{node}\ (s, [(s,e)^*], t)
\end{align*}
A template $t$ is a list of template parts $p$, which can be a string literal
$s$, an interpolated expression $e$, or an attributed tagged tree \kw{node}. For
example, a section can be represented as \kw{node} (\lstinline{"section"},
[(\lstinline{"id"}, 0)], [\lstinline{"title"}]), where an attribute called
\lstinline{"id"} is attached. The syntax of \ExT is almost the same: an
interpolated expression is denoted by \lstinline{\(e)}, and an attributed tagged
tree is like \lstinline|\Section{id=0}[title]|.

\paragraph{Computation in \ExT.}
Relating \ExT to \DArtTLit is not particularly interesting because the ability
to perform general-purpose computation in \ExT is not captured in \DArtTLit.
\DArtTProg extends \DArtTLit with template programs, namely three new template
parts: $\kw{set}\ x = e$, $\kw{if}\ e\ \kw{then}\ t_1\ \kw{else}\ t_2$, and
$\kw{foreach}\ e\ \{x.\,t\}$. Although \ExT does not support these constructs
directly, we can simulate the latter two by implementing customized commands. In
other words, \kw{if}-expressions and \kw{foreach}-loops can be encoded as
special \kw{node}s. A simplified code snippet for such encodings is shown below:
\begin{lstlisting}[literate={``}{{\textasciigrave}}1]
-- \If(cond)[then][else]
If (b: Bool) (t: Element) (e: Element) = trait => if b then t else e;
-- \Foreach@Type(array)(func)
Foreach A (xs: [A]) (f: A -> Element) = trait =>
  letrec go (i: Int): Element = if i == #xs then Str ""
                                else Comp (f (xs!!i)) (go (i+1)) in go 0;
...
fruits = [ "apple"; "banana"; "cherry" ];  -- \Set is not encodable yet
...
`\Itemize[\Foreach@String(fruits)(\(x: String) ->
    ``\If(x == "apple")[][\Item[\(x)]]``
)]`
\end{lstlisting}
However, encoding the \kw{set}-statement is much more challenging, because
variable binding is difficult, if not impossible, to implement in the userland.
Notwithstanding this minor mismatch, it is worth investigating how to build a
formal correspondence between \ExT and \DArtTProg and show that \ExT is as
expressive as an article template program DSL.

\section{Improving the CP Compiler}

\paragraph{Side effects in top-like terms.}
Our formalization of \lambdaiplus follows the distributive subtyping rules
proposed by \citet{barendregt1983filter}, which allows the top type $\top$ to be
a subtype of $\top \to \top$. Via transitivity and contravariance of functions,
we can show that $\top$ is a subtype of any function type returning $\top$:
\begin{mathpar}
\inferrule*[right=S-Trans]{\top \sub \top \to \top \\
                           \inferrule*[right=S-Fun]{A <: \top \\ \top <: \top}
                                                   {\top \to \top \sub A \to \top}}
                          {\top \sub A \to \top}
\end{mathpar}
This relation can be understood as a generalization of the distributive
subtyping rule for function types, where $n = 0$:
\begin{equation*}
(A \to B_1) \tand (A \to B_2) \tand \cdots \tand (A \to B_n)
\sub A \to (B_1 \tand B_2 \tand \cdots \tand B_n)
\end{equation*}
Since $\top$ represents the 0-ary intersection, the relation above is simplified
to $\top \sub A \to \top$. The other direction $A \to \top \sub \top$ also holds
because any type is a subtype of the maximal type $\top$. This means that $A \to
\top$ is equivalent to $\top$ and is called \emph{top-like} (i.e. $\rceil A \to
\top \lceil$) in \autoref{fig:disj}.

In our elaboration rules, all top-like terms are treated as $\top$ and
elaborated to an empty record (see \rref{Ela-Top,Ela-TopAbs,Ela-TopRcd}).
Moreover, the coercive subtyping \rref{S-Top} in coerce a target term to an
empty record if $B$ is top-like in $A <: B$. As a result, side effects in
top-like terms are erased during elaboration, which is not desired in imperative
languages. For example, $(\lambda r.\ r := 1) : \mathbf{Ref}\ \mathbb{Z} \to
\top$ is elaborated to $\{\}$, and the original function is erased. So the
reference $r$ will never be updated when the coerced function is applied.

One obvious solution is not to erase the top-like terms during the elaboration.
For example, we can elaborate the previous expression to $\{|\mathbf{Ref}\
\mathbb{Z} \to \top| \Mapsto \lambda r.\ \epsilon\}$, assuming $r := 1$ is
elaborated to $\epsilon$. We also need to revise the \rref{A-Top} to call the
function rather than just return an empty record. However, this change breaks
the current definition of equivalent types (informally in \autoref{sec:eqty} and
formally in \autoref{fig:source-equiv}) because different top-like terms can
have different representations now. Coercions between top-like terms cannot be
eliminated because, for example, $\{|\top| \Mapsto \dots\}$ is different from
$\{|\mathbf{Ref}\ \mathbb{Z} \to \top| \Mapsto \dots\}$. An immediate follow-up
question is how to correctly coerce $\lambda r.\ r := 1$ to type $\top$ or
$\{\ell:\top\}$, both of which are supertypes of $\mathbf{Ref}\ \mathbb{Z} \to
\top$.

A first try is to keep the term intact while only changing the type indices. For
example, $\{|\top| \Mapsto \lambda r.\ \epsilon\}$ and $\{|\{\ell:\top\}|
\Mapsto \lambda r.\ \epsilon\}$ can be the results of the above-mentioned
coercions. However, how to project the latter term by label $\ell$ is not clear
then. Of course, we can do nothing and still keep the term intact, but consider
another source term $\mathbf{let}\ r = \mathbf{ref}\ 0\ \mathbf{in}\ \{\ell = (r
:= 1)\} : \{\ell:\top\}$. This term also has type $\{\ell:\top\}$, but we expect
projecting it by $\ell$ will assign $1$ to $r$ instead of doing nothing.
Therefore, there is no trivial way to revise the \rref{P-Top} (and the
\rref{A-Top} similarly).

As discussed briefly above, we believe that it is challenging to redesign the
relevant rules to support side effects in top-like terms, so we leave it for
future work.

\paragraph{Side effects with unrestricted intersection types.}
In this thesis, we allow unrestricted intersection types like
$\mathbb{Z}\tand\mathbb{Z}$. When coercing a term of type $\mathbb{Z}$ into
$\mathbb{Z}\tand\mathbb{Z}$, the content of the term is duplicated. If there are
side effects in the term, they will be executed twice too. This problem is
similar to the one discussed previously on top-like terms: side effects are
unexpectedly erased there and duplicated here. We can fix the issue by
restricting the intersection types and thus disallowing types like
$\mathbb{Z}\tand\mathbb{Z}$. \citet{ye2024imperative} employed this approach in
their work on distributive intersection subtyping for imperative languages.
However, this restriction reduces the expressiveness of the language, so this
thesis does not adopt it. We leave for future work the exploration of a solution
that allows unrestricted intersections while avoiding the unexpected duplication
of side effects.

\paragraph{Reconciliation between eagerness and laziness.}
As observed by \citet{fan2022direct}, trait instantiation may diverge in CP if a
call-by-value evaluation strategy is used. Several years ago, a
similar observation was made by \citet{bruce1999comparing} in the context of
object encodings. \citeauthor{fan2022direct} fixed the divergence issue by
switching to a call-by-name evaluation strategy completely, which is inefficient
in practice. That is why we turn to a hybrid strategy: only self-annotated trait
fields are lazily evaluated, as shown in \autoref{fig:call-by-need}, and other
constructs are eagerly evaluated. Our hybrid approach is implemented in the CP
compiler and proves to be effective in practice, but it has not been formalized
or well studied. It is worthwhile to investigate formal semantics with the
hybrid evaluation strategy and see how it can be applied to other languages.

First, let us review why the trait instantiation does not terminate with the
call-by-value strategy. The example used for \autoref{fig:call-by-need}
corresponds to the following code using the fixpoint operator, and it reduces as
follows:
\begin{lstlisting}
    fix this. { x = this.y; y = 48 }
|-> { x = (fix this. { x = this.y; y = 48 }).y; y = 48 }
|-> { x = { x = (fix this. { x = this.y; y = 48 }).y; y = 48 }.y; y = 48 }
|-> ...
\end{lstlisting}
The evaluation diverges because the variable \lstinline{this} is evaluated
repeatedly, despite the fact that only \lstinline{this.y} is needed. Therefore,
we can conclude that the key to laziness is: do not evaluate anything until it
is needed.

The solution employed in the CP compiler uses smart getters in JavaScript, which
are essentially adding \emph{thunks} to certain record fields. A natural
direction is to formalize the semantics using the call-by-push-value
model~\citep{levy2012call}. For example, the previous example can be rewritten
to the following form:
\begin{lstlisting}[morekeywords=thunk]
    fix this. { x = thunk this.y; y = 48 }
|-> { x = thunk (fix this. { x = this.y; y = 48 }).y; y = 48 }
\end{lstlisting}
The evaluation terminates because the thunk is already a value of type $U (F\
\mathbb{Z})$, meaning a thunk that returns an integer. To obtain the integer
value from the \lstinline{x} field, we have to force the thunk, while the
\lstinline{y} field can be directly accessed. This difference can be detected
statically by their types: \lstinline{x} has type $U (F\ \mathbb{Z})$ while
\lstinline{y} has type $\mathbb{Z}$. Therefore, we probably need different
projection rules for different types of fields. We leave further exploration of
this topic for future work.

\paragraph{A variant of destination-passing style without optional destinations.}
In \autoref{sec:dst}, we mention that there are three forms of destinations:
$z$, $y?$, and \textbf{nil}, where $y?$ represents an optional destination in
the context of a function body. An alternative approach that avoids the case of
optional destinations is to compile each function twice: one with a destination
and the other without (see \textsc{J-Abs} in \autoref{fig:dst-nodst}).
Correspondingly, we need to change the rules for function application to choose
the appropriate version of a function statically (see \textsc{JA-ArrowEquiv} and
\textsc{JA-ArrowNil} in \autoref{fig:dst-nodst}).

Although this approach doubles the compilation time of a function body and
duplicates every function definition in compiled code, it reduces the overhead
of dynamic checks for optional destinations at run time. A quantitative analysis
is needed to compare the two approaches in terms of time and space complexity.
We leave this evaluation for future work.

\begin{figure}
\small
\begin{align*}
  &\text{Destinations}&\textit{dst} ::=&~ \ottkw{nil} ~|~ \ottmv{z} \\
\end{align*}
\begin{ottdefnblock}{\compilation}{\ottcom{Type-directed compilation}}
  \inferrule[J-Abs]
  {\Gamma  \ottsym{,}  \ottmv{x}  \ottsym{:}  \ottnt{A}  \ottsym{;}  \ottmv{z}  \vdash  \ottnt{e} \, \Leftarrow \, \ottnt{B}  \, \rightsquigarrow \,  \texttt{J}  \; | \;  \ottmv{z} \\
   \Gamma  \ottsym{,}  \ottmv{x}  \ottsym{:}  \ottnt{A}  \ottsym{;}  \ottkw{nil}  \vdash  \ottnt{e} \, \Leftarrow \, \ottnt{B}  \, \rightsquigarrow \,  \texttt{J}  \; | \;  \ottmv{y}}
  {\Gamma  \ottsym{;}  \ottmv{z}  \vdash   \lambda \ottmv{x} \!:\! \ottnt{A} .\; \ottnt{e} \!:\! \ottnt{B}  \, \Rightarrow \, \ottnt{A}  \rightarrow  \ottnt{B}  \, \rightsquigarrow \\\\
   \highlight{\texttt{z["func\_|B|\_dst"] = (x, z) => \{ J \};}} \\\\
   \highlight{\texttt{z["func\_|B|\_nodst"] = (x) => \{ J; return y; \};}}  \; | \;  \ottmv{z}}
\end{ottdefnblock}
\begin{ottdefnblock}{\application}{\ottcom{Function application}}
  \inferrule[JA-ArrowEquiv]
  {\ottnt{A}  \fallingdotseq  \ottnt{C}}
  {\Gamma  \ottsym{;}  \ottmv{z}  \vdash  \ottmv{x}  \ottsym{:}  \ottnt{A}  \rightarrow  \ottnt{B}  \, \bullet \,  \ottmv{y}  \ottsym{:}  \ottnt{C}  \, \rightsquigarrow \\\\
   \highlight{\texttt{x["func\_|B|\_dst"](y, z);}}  \; | \;  \ottmv{z}  \ottsym{:}  \ottnt{B}}

  \inferrule[JA-ArrowNil]
  {\ottnt{A}  \fallingdotseq  \ottnt{C}}
  {\Gamma  \ottsym{;}  \ottkw{nil}  \vdash  \ottmv{x}  \ottsym{:}  \ottnt{A}  \rightarrow  \ottnt{B}  \, \bullet \,  \ottmv{y}  \ottsym{:}  \ottnt{C}  \, \rightsquigarrow \\\\
   \highlight{\texttt{var z = x["func\_|B|\_nodst"](y);}}  \; | \;  \ottmv{z}  \ottsym{:}  \ottnt{B}}
\end{ottdefnblock}
\caption{A variant of destination-passing style without optional destinations.} \label{fig:dst-nodst}
\end{figure}

\paragraph{Representation of type indices.}
As discussed in \autoref{sec:index}, we use a shorter representation for
function types in our implementation, which only includes the return type.
However, there are some rare corner cases where this design causes trouble. Here
is an example:
\begin{lstlisting}
type A = (Int -> Int&Bool) -> Int;
type B = (Int -> Int&String) -> Int;
f (g: Int -> Int) = g 0;
f' = f : A&B;
f'' = f' : A;
f'' (\(x:Int) -> x,true)
\end{lstlisting}
Although the types of components of a merge are guaranteed to be disjoint, there
is no rule guaranteeing components of an intersection type to be disjoint.
Therefore, we can duplicate the function by casting \lstinline{f} to type
\lstinline{A&B}. Since \lstinline{A} and \lstinline{B} are not disjoint and have
the same return type, they would share the same type index
\lstinline{"func_int"}. We could not distinguish them by type indices, and the
field for \lstinline{f:B} would override that for \lstinline{f:A} in our
implementation. At first sight, it somehow makes sense because they are
essentially the same function so we do not need to keep two copies. However, the
trouble here is that their parameters have different type indices:
\lstinline{"func_(bool&int)"} for \lstinline{A}'s parameter and
\lstinline{"func_(int&string)"} for \lstinline{B}'s. This subtle difference
leads to slightly different compilation results for \lstinline{f:A} and
\lstinline{f:B}. The code above would go wrong as we do not distinguish them and
misuse \lstinline{f:B} as \lstinline{f:A}.

The fix is easy. Our formalization in \autoref{ch:calculi} uses a more
precise representation for function types: both the parameter and return types
are included in the type indices. Nevertheless, the issue is rare, and we
have never encountered such a case in benchmarks. For the considerations of
performance and code size, we still use the shorter type indices that only
include return types in our implementation. It is worthwhile to investigate the
trade-off between soundness and performance in the representation of type
indices. For example, we can use bit sets to represent intersection types.

\section{Mixing Named and Positional Arguments}

As shown in \autoref{tab:survey}, CP advocate distinctness between named and
positional arguments. An interesting direction worth exploring is to drop
distinctness. By this means, we can support omitting keywords if the order of
arguments is not changed from how they are defined. However, mixing positional
and named arguments arbitrarily can lead to confusion. For example, consider the
following pseudo-Python function:
\begin{lstlisting}[language={[3]Python}]
def f(x=1, y, z): ...
f(y=2, 3, 4)
\end{lstlisting}
It is not clear which parameters \lstinline{3} and \lstinline{4} in the function
call correspond to, though \lstinline{f(x=3, y=2, z=4)} could be a plausible
interpretation. In fact, Python syntactically rejects the code for two reasons:
\begin{enumerate}
\item The parameters without default values (\lstinline{y} and \lstinline{z})
      should not follow a parameter with a default value (\lstinline{x=1}) in
      the function definition.
\item Positional arguments (\lstinline{3} and \lstinline{4}) should not follow
      a keyword argument (\lstinline{y=2}) in the call site.
\end{enumerate}
These two restrictions are reasonable and largely improve the code clarity with
named and positional arguments mixed. Nevertheless, these restrictions are not
necessarily the best because they are too strict. For example, Scala enforces
neither restriction for more flexibility. Although the previous confusing code
is also rejected by Scala, the following code is valid:
\begin{lstlisting}[language=Scala,otherkeywords={}]
def f(a: Int, b: Int, c: Int = 3, d: Int, e: Int) = ...
f(1, d=4, b=2, 5)  //= f(a=1, b=2, c=3, d=4, e=5)
\end{lstlisting}
Although this code is clear in general, its counterpart in Python is invalid
because \lstinline{d} and \lstinline{e} cannot follow \lstinline{c=3} in the
function definition and \lstinline{5} cannot follow \lstinline{b=2} in the call
site. In contrast, Scala lifts these restrictions and enforces a weaker one.
Unfortunately, neither the official
documentation\footnote{\url{https://docs.scala-lang.org/tour/named-arguments.html}:
\emph{``Once the arguments are not in parameter order, reading from left to
right, then the rest of the arguments must be named.''}} nor the language
specification\footnote{\url{https://www.scala-lang.org/files/archive/spec/3.4/06-expressions.html\#named-and-default-arguments}:
\emph{``For every named argument $p_i = e_i$ which appears left of a positional
argument in the argument list $e_1 \dots e_m$, the argument position $i$
coincides with the position of parameter $p_i$ in the parameter list of the
applied method.''}} can explain why the code above is valid in Scala. According
to either description, the code should be rejected. Here we try to give an
intuitive description that is inferred from our experimental observations:
\begin{quoting}
For any named argument $p_i = e_i$, positional arguments to the right ($e_j,
j>i$) should correspond to formal parameters to the right of $p_i$ in the
function definition. The same applies to the positional arguments to the left.
\end{quoting}
No matter how the restriction is formulated, and whether it is stricter or
weaker, this is an important first step for the design of the source language
with named and positional arguments mixed. We can give semantics to the source
language by translating it to \lambdaiu, which is similar to what happens in
Scala. The translation should be purely syntax-directed. By this means, we
obtain a more flexible language without changing the type-theoretic foundation
at all.
