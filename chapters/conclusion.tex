\chapter{Conclusion and Future Work} \label{ch:conclusion}

In the following sections, we discuss some future directions that are worth
exploring.

\section{Formalizing the Document DSL}

\newcommand{\DArtTLit}{$\mathcal{D}^\mathsf{Article}_\mathsf{TLit}$\xspace}
\newcommand{\DArtTProg}{$\mathcal{D}^\mathsf{Article}_\mathsf{TProg}$\xspace}
\newcommand{\kw}[1]{\text{\ttfamily\bfseries #1}}

\ExT, introduced in \autoref{sec:dsl}, is a powerful document DSL that supports
general-purpose computation. However, we only give an informal description of
\ExT without formalizing its semantics. Recently, \citet{crichton2024core}
proposed a core calculus for documents and provided a formal semantics for it.
It would be interesting to investigate the relationship between our \ExT and
their document calculus.

\citeauthor{crichton2024core} classified documents into eight levels based on
the document domain and expressiveness. According to their taxonomy, \ExT
corresponds to the article template literal calculus \DArtTLit, meaning that the
documents generated by \ExT are annotated trees of strings (called
``articles''), and documents are constructed of article literals with
interpolation, similar to Scribble in Racket.

To better understand the document calculus, we restate the definition of
templates in \DArtTLit below:
\begin{align*}
\mathsf{Template}^\mathsf{Article}_\mathsf{TLit} \; t&::= [p^*] \\
   \mathsf{TPart}^\mathsf{Article}_\mathsf{TLit} \; p&::= s ~|~ e ~|~ \kw{node}\ (s, [(s,e)^*], t)
\end{align*}
A template $t$ is a list of template parts $p$, which can be a string literal
$s$, an interpolated expression $e$, or an attributed tagged tree \kw{node}. For
example, a section can be represented as \kw{node} (\lstinline{"section"},
[(\lstinline{"id"}, 0)], [\lstinline{"title"}]), where an attribute called
\lstinline{"id"} is attached. The syntax of \ExT is almost the same: an
interpolated expression is denoted by \lstinline{\(e)}, and an attributed tagged
tree is like \lstinline|\Section{id=0}[title]|.

\paragraph{Computation in \ExT.}
Relating \ExT to \DArtTLit is not particularly interesting because the ability
to perform general-purpose computation in \ExT is not captured in \DArtTLit.
\DArtTProg extends \DArtTLit with template programs, namely three new template
parts: $\kw{set}\ x = e$, $\kw{if}\ e\ \kw{then}\ t_1\ \kw{else}\ t_2$, and
$\kw{foreach}\ e\ \{x.\,t\}$. Although \ExT does not support these constructs
directly, we can simulate the latter two by implementing customized commands. In
other words, \kw{if}-expressions and \kw{foreach}-loops can be encoded as
special \kw{node}s. A simplified code snippet for such encodings is shown below:
\begin{lstlisting}[literate={``}{{\textasciigrave}}1]
-- \If(cond)[then][else]
If (b: Bool) (t: Element) (e: Element) = trait => if b then t else e;
-- \Foreach@Type(array)(func)
Foreach A (xs: [A]) (f: A -> Element) = trait =>
  letrec go (i: Int): Element = if i == #xs then Str ""
                                else Comp (f (xs!!i)) (go (i+1)) in go 0;
...
fruits = [ "apple"; "banana"; "cherry" ];  -- \Set is not encodable yet
...
`\Itemize[\Foreach@String(fruits)(\(x: String) ->
    ``\If(x == "apple")[][\Item[\(x)]]``
)]`
\end{lstlisting}
However, encoding the \kw{set}-statement is much more challenging, because
variable binding is difficult, if not impossible, to implement in the userland.
Notwithstanding this minor mismatch, it is worth investigating how to build a
formal correspondence between \ExT and \DArtTProg and show that \ExT is as
expressive as an article template program DSL.

\section{Improving the CP Compiler}

\paragraph{Side effects in top-like terms.}
Our formalization of \lambdaiplus follows the distributive subtyping rules
proposed by \citet{barendregt1983filter}, which allows the top type $\top$ to be
a subtype of $\top \to \top$. Via transitivity and contravariance of functions,
we can show that $\top$ is a subtype of any function type returning $\top$:
\begin{mathpar}
\inferrule*[right=S-Trans]{\top \sub \top \to \top \\
                           \inferrule*[right=S-Fun]{A <: \top \\ \top <: \top}
                                                   {\top \to \top \sub A \to \top}}
                          {\top \sub A \to \top}
\end{mathpar}
This relation can be understood as a generalization of the distributive
subtyping rule for function types, where $n = 0$:
\begin{equation*}
(A \to B_1) \tand (A \to B_2) \tand \cdots \tand (A \to B_n)
\sub A \to (B_1 \tand B_2 \tand \cdots \tand B_n)
\end{equation*}
Since $\top$ represents the 0-ary intersection, the relation above is simplified
to $\top \sub A \to \top$. The other direction $A \to \top \sub \top$ also holds
because any type is a subtype of the maximal type $\top$. This means that $A \to
\top$ is equivalent to $\top$ and is called \emph{top-like} (i.e. $\rceil A \to
\top \lceil$) in \autoref{fig:disj}.

In our elaboration rules, all top-like terms are treated as $\top$ and
elaborated to an empty record (see \rref{Ela-Top,Ela-TopAbs,Ela-TopRcd}).
Moreover, the coercive subtyping \rref{S-Top} in coerce a target term to an
empty record if $B$ is top-like in $A <: B$. As a result, side effects in
top-like terms are erased during elaboration, which is not desired in imperative
languages. For example, $(\lambda r.\ r := 1) : \mathbf{Ref}\ \mathbb{Z} \to
\top$ is elaborated to $\{\}$, and the original function is erased. So the
reference $r$ will never be updated when the coerced function is applied.

One obvious solution is not to erase the top-like terms during the elaboration.
For example, we can elaborate the previous expression to $\{|\mathbf{Ref}\
\mathbb{Z} \to \top| \Mapsto \lambda r.\ \epsilon\}$, assuming $r := 1$ is
elaborated to $\epsilon$. We also need to revise the \rref{A-Top} to call the
function rather than just return an empty record. However, this change breaks
the current definition of equivalent types (informally in \autoref{sec:eqty} and
formally in \autoref{fig:source-equiv}) because different top-like terms can
have different representations now. Coercions between top-like terms cannot be
eliminated because, for example, $\{|\top| \Mapsto \dots\}$ is different from
$\{|\mathbf{Ref}\ \mathbb{Z} \to \top| \Mapsto \dots\}$. An immediate follow-up
question is how to correctly coerce $\lambda r.\ r := 1$ to type $\top$ or
$\{\ell:\top\}$, both of which are supertypes of $\mathbf{Ref}\ \mathbb{Z} \to
\top$.

A first try is to keep the term intact while only changing the type indices. For
example, $\{|\top| \Mapsto \lambda r.\ \epsilon\}$ and $\{|\{\ell:\top\}|
\Mapsto \lambda r.\ \epsilon\}$ can be the results of the above-mentioned
coercions. However, how to project the latter term by label $\ell$ is not clear
then. Of course, we can do nothing and still keep the term intact, but consider
another source term $\mathbf{let}\ r = \mathbf{ref}\ 0\ \mathbf{in}\ \{\ell = (r
:= 1)\} : \{\ell:\top\}$. This term also has type $\{\ell:\top\}$, but we expect
projecting it by $\ell$ will assign $1$ to $r$ instead of doing nothing.
Therefore, there is no trivial way to revise the \rref{P-Top} (and the
\rref{A-Top} similarly).

As discussed briefly above, we believe that it is challenging to redesign the
relevant rules to support side effects in top-like terms, so we leave it for
future work.

\paragraph{Reconciliation between eagerness and laziness.}
As observed by \citet{fan2022direct}, trait instantiation may diverge in CP if a
call-by-value evaluation strategy is used. More than a score of years ago, a
similar observation was made by \citet{bruce1999comparing} in the context of
object encodings. \citeauthor{fan2022direct} fixed the divergence issue by
switching to a call-by-name evaluation strategy completely, which is inefficient
in practice. That is why we turn to a hybrid strategy: only self-annotated trait
fields are lazily evaluated, as shown in \autoref{fig:call-by-need}, and other
constructs are eagerly evaluated. Our hybrid approach is implemented in the CP
compiler and proves to be effective in practice, but it has not been formalized
or well studied. It is worthwhile to investigate formal semantics with the
hybrid evaluation strategy and see how it can be applied to other languages.

First, let us review why the trait instantiation does not terminate with the
call-by-value strategy. The example used for \autoref{fig:call-by-need}
corresponds to the following code using the fixpoint operator, and it reduces as
follows:
\begin{lstlisting}
    fix this. { x = this.y; y = 48 }
|-> { x = (fix this. { x = this.y; y = 48 }).y; y = 48 }
|-> { x = { x = (fix this. { x = this.y; y = 48 }).y; y = 48 }.y; y = 48 }
|-> ...
\end{lstlisting}
The evaluation diverges because the variable \lstinline{this} is evaluated
repeatedly, despite the fact that only \lstinline{this.y} is needed. Therefore,
we can conclude that the key to laziness is: do not evaluate anything until it
is needed.

The solution employed in the CP compiler uses smart getters in JavaScript, which
is essentially adding \emph{thunks} to certain record fields. For example, the
previous example will be rewritten to something like:
\begin{lstlisting}
    fix this. { x = \() -> this.y; y = 48 }
|-> { x = \() -> (fix this. { x = this.y; y = 48 }).y; y = 48 }
\end{lstlisting}
The evaluation terminates because the thunk \lstinline{\() -> (fix ...).y} is
already a value. A consequence of this approach is that when accessing the
\lstinline{x} field, we have to invoke the thunk using \lstinline{r.x ()}
instead of directly using \lstinline{r.x}. This is easy to implement in CP since
we are compiling the source code to another language and consistently adding
thunks and invocations in that language. However, it is difficult to formalize a
hybrid semantics that combines eagerness and laziness directly for the source
language.

A natural direction is to integrate the call-by-push-value
model~\citep{levy2012call}, which reconciles the call-by-value and call-by-name
strategies. We leave this exploration for future work.

\paragraph{Representation of type indices.}
As discussed in \autoref{sec:index}, we use a shorter representation for
function types in our implementation, which only includes the return type.
However, there are some rare corner cases where this design causes trouble. Here
is an example:
\begin{lstlisting}
type A = (Int -> Int&Bool) -> Int;
type B = (Int -> Int&String) -> Int;
f (g: Int -> Int) = g 0;
f' = f : A&B;
f'' = f' : A;
f'' (\(x:Int) -> x,true)
\end{lstlisting}
Although the types of components of a merge are guaranteed to be disjoint, there
is no rule guaranteeing components of an intersection type to be disjoint.
Therefore, we can duplicate the function by casting \lstinline{f} to type
\lstinline{A&B}. Since \lstinline{A} and \lstinline{B} are not disjoint and have
the same return type, they would share the same type index
\lstinline{"func_int"}. We could not distinguish them by type indices, and the
field for \lstinline{f:B} would override that for \lstinline{f:A} in our
implementation. At first sight, it somehow makes sense because they are
essentially the same function so we do not need to keep two copies. However, the
trouble here is that their parameters have different type indices:
\lstinline{"func_(bool&int)"} for \lstinline{A}'s parameter and
\lstinline{"func_(int&string)"} for \lstinline{B}'s. This subtle difference
leads to slightly different compilation results for \lstinline{f:A} and
\lstinline{f:B}. The code above would go wrong as we do not distinguish them and
misuse \lstinline{f:B} as \lstinline{f:A}.

The fix can be easy. Our formalization in \autoref{ch:calculi} uses a more
precise representation for function types: both the parameter and return types
are included in the type indices. Nevertheless, the issue is really rare, and we
have never encountered such a case in benchmarks. For the considerations of
performance and code size, we still use the shorter type indices that only
include return types in our implementation. It is worthwhile to investigate the
trade-off between soundness and performance in the representation of type
indices. For example, we can use bit sets to represent intersection types.

\section{Mixing Named and Positional Arguments}

As shown in \autoref{tab:survey}, CP advocate distinctness between named and
positional arguments. An interesting direction worth exploring is to drop
distinctness. By this means, we can support omitting keywords if the order of
arguments is not changed from how they are defined. However, mixing positional
and named arguments can easily lead to ambiguity, especially when some arguments
are optional. An important first step is to find an appropriate restriction that
we should impose to mitigate the ambiguity problem.

One possibility is to follow the restriction in Python: ...
